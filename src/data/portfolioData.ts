/// <reference path="../declarations.d.ts" />
import virginia_tech from "../assets/virginia-tech.png";
import aied from "../assets/aied-2023.png";
import hcii from "../assets/hcii-2024.png";

export default [
  {
    title: "HCII 2024 Conference Paper",
    subtitle:
      "Exploring Explainability and Transparency in Automated Essay Scoring Systems",
    description:
      "In recent years, rapid advancements in computer science, including increased capabilities of machine learning models like Large Language Models (LLMs) and the accessibility of large datasets, have facilitated the widespread adoption of AI technology, underscoring the need to ethically design and evaluate these technologies with concern for their impact on students and teachers. Specifically, the rise of Automated Essay Scoring (AES) platforms have made it possible to provide real-time feedback and grades for student essays. Despite the increasing development and use of AES platforms, limited research has focused on AI explainability and algorithm transparency and their influence on the usability of these platforms. To address this gap, we conducted a qualitative study on an AI-based essay writing and grading platform, Packback Deep Dives, with a primary focus of exploring the experiences of students and graders. The study aimed to explore the system’s usability related to explainability and transparency and to uncover the resulting implications for users. Participants took part in surveys, semi-structured interviews, and a focus group. The findings reveal several important considerations for evaluating AES systems, including the clarity of feedback and explanations, effectiveness and actionability of feedback and explanations, perceptions and misconceptions of the system, evolving trust in AI judgments, user concerns and fairness perceptions, system efficiency and feedback quality, user interface accessibility and design, and system enhancement design priorities. These proposed key considerations can help guide the development of effective essay feedback and grading tools that prioritize explainability and transparency to improve usability.",
    image: hcii,
    links: [
      {
        label: "View DOI",
        url: "https://doi.org/10.1007/978-3-031-61691-4_18",
      },
    ],
  },
  {
    title: "Master's Thesis",
    subtitle:
      "A User-Centered Design Approach to Evaluating the Usability of Automated Essay Scoring Systems",
    description:
      "In recent years, rapid advancements in computer science, including increased capabilities of machine learning models like Large Language Models (LLMs) and the accessibility of large datasets, have facilitated the widespread adoption of AI technology, such as ChatGPT, underscoring the need to design and evaluate these technologies with ethical considerations for their impact on students and teachers. Specifically, the rise of Automated Essay Scoring (AES) platforms have made it possible to provide real-time feedback and grades for student essays. Despite the increasing development and use of AES platforms, limited research has specifically focused on AI explainability and algorithm transparency and their influence on the usability of these platforms. To address this gap, we conducted a qualitative study on an AI-based essay writing and grading platform, with a primary focus to explore the experiences of students and graders. The study aimed to explore the usability aspects related to explainability and transparency and their implications for computer science education. Participants took part in surveys, semi-structured interviews, and a focus group. The findings reveal important considerations for evaluating AES systems, including the clarity of feedback and explanations, impact and actionability of feedback and explanations, user understanding of the system, trust in AI, major issues and user concerns, system strengths, user interface, and areas of improvement. These proposed key considerations can help guide the development of effective essay feedback and grading tools that prioritize explainability and transparency to improve usability in computer science education.",
    image: virginia_tech,
    links: [
      {
        label: "View Thesis (PDF)",
        url: "https://vtechworks.lib.vt.edu/server/api/core/bitstreams/12ad03cd-5041-446e-aee9-097ad1d6c617/content",
      },
    ],
  },
  {
    title: "AIED 2023 Conference Paper",
    subtitle:
      "Identifying Usability Challenges in AI-Based Essay Grading Tools",
    description:
      "Automated Essay Scoring (AES) efforts have recently made it possible for platforms to provide real-time feedback and grades for student essays. With the growing importance of addressing usability issues that arise from integrating artificial intelligence (AI) into educational-based platforms, there have been significant efforts to improve the visual elements of User Interfaces (UI) for these types of platforms. However, little research has been done on how AI explainability and algorithm transparency affect the usability of AES platforms. To address this gap, a qualitative study was conducted using an AI-driven essay writing and grading platform. The study involved participants of students and instructors, and utilized surveys, semi-structured interviews, and a focus group to collect data on users’ experiences and perspectives. Results show that user understanding of the system, quality of feedback, error handling, and creating trust are the main usability concerns related to explainability and transparency. Understanding these challenges can help guide the development of effective grading tools that prioritize explainability and transparency, ultimately improving their usability.",
    image: aied,
    links: [
      {
        label: "View DOI",
        url: "https://doi.org/10.1007/978-3-031-36336-8_104",
      },
    ],
  },
];
